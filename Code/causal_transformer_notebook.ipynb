{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual RUL Estimation Using Causal Transformers\n",
    "## A Structural Intervention Framework for Milling Tool Degradation (PHM 2010 Benchmark)\n",
    "\n",
    "**Author:** Muhammad Umar  \n",
    "**Affiliation:** University of Ulsan, South Korea\n",
    "\n",
    "---\n",
    "\n",
    "This notebook implements:\n",
    "1. **Baseline Transformer** - High-accuracy RUL prediction\n",
    "2. **Causal-Structural Transformer** - Explainable RUL with counterfactual capabilities\n",
    "3. **What-If Analysis** - Evaluate alternative machining strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import our modules\n",
    "from phm2010_data_loader import PHM2010DataLoader\n",
    "from causal_transformer_rul import (\n",
    "    BaselineTransformer,\n",
    "    CausalStructuralTransformer,\n",
    "    PHM2010Dataset,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    visualize_causal_decomposition,\n",
    "    perform_counterfactual_analysis,\n",
    "    visualize_counterfactual_results,\n",
    "    plot_training_curves,\n",
    "    plot_predictions_comparison,\n",
    "    device\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Data parameters\n",
    "    'data_path': r'E:\\Collaboration Work\\With Farooq\\phm dataset\\PHM Challange 2010 Milling',\n",
    "    'sequence_length': 20,\n",
    "    'stride': 1,\n",
    "    'train_ratio': 0.7,\n",
    "    'val_ratio': 0.15,\n",
    "    \n",
    "    # Model parameters\n",
    "    'd_model': 128,\n",
    "    'nhead': 8,\n",
    "    'num_layers': 4,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 15,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = PHM2010DataLoader(CONFIG['data_path'])\n",
    "\n",
    "# Prepare data\n",
    "data_dict = loader.prepare_data(\n",
    "    sequence_length=CONFIG['sequence_length'],\n",
    "    stride=CONFIG['stride'],\n",
    "    train_ratio=CONFIG['train_ratio'],\n",
    "    val_ratio=CONFIG['val_ratio']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "train_seq, train_labels, train_cond, train_hi = data_dict['train']\n",
    "val_seq, val_labels, val_cond, val_hi = data_dict['val']\n",
    "test_seq, test_labels, test_cond, test_hi = data_dict['test']\n",
    "\n",
    "input_dim = train_seq.shape[2]\n",
    "num_conditions = len(data_dict['condition_mapping'])\n",
    "\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Number of conditions: {num_conditions}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PHM2010Dataset(train_seq, train_labels, train_cond, train_hi)\n",
    "val_dataset = PHM2010Dataset(val_seq, val_labels, val_cond, val_hi)\n",
    "test_dataset = PHM2010Dataset(test_seq, test_labels, test_cond, test_hi)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Baseline Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize baseline model\n",
    "baseline_model = BaselineTransformer(\n",
    "    input_dim=input_dim,\n",
    "    d_model=CONFIG['d_model'],\n",
    "    nhead=CONFIG['nhead'],\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Baseline model parameters: {sum(p.numel() for p in baseline_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "baseline_train_losses, baseline_val_losses = train_model(\n",
    "    baseline_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    model_type='baseline',\n",
    "    patience=CONFIG['patience']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model\n",
    "baseline_preds, baseline_actuals, baseline_metrics = evaluate_model(\n",
    "    baseline_model, test_loader, model_type='baseline'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Causal-Structural Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize causal model\n",
    "causal_model = CausalStructuralTransformer(\n",
    "    input_dim=input_dim,\n",
    "    num_conditions=num_conditions,\n",
    "    d_model=CONFIG['d_model'],\n",
    "    nhead=CONFIG['nhead'],\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout'],\n",
    "    enforce_physics=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"Causal model parameters: {sum(p.numel() for p in causal_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train causal model\n",
    "causal_train_losses, causal_val_losses = train_model(\n",
    "    causal_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    model_type='causal',\n",
    "    patience=CONFIG['patience']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate causal model\n",
    "causal_preds, causal_actuals, causal_metrics = evaluate_model(\n",
    "    causal_model, test_loader, model_type='causal'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline Transformer', 'Causal-Structural Transformer'],\n",
    "    'MAE (cuts)': [baseline_metrics['mae'], causal_metrics['mae']],\n",
    "    'RMSE (cuts)': [baseline_metrics['rmse'], causal_metrics['rmse']],\n",
    "    'MAPE (%)': [baseline_metrics['mape'], causal_metrics['mape']]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "comparison_df.set_index('Model')[['MAE (cuts)', 'RMSE (cuts)']].plot(kind='bar', ax=ax)\n",
    "ax.set_ylabel('Error (cuts)')\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, weight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(\n",
    "    (baseline_train_losses, baseline_val_losses),\n",
    "    (causal_train_losses, causal_val_losses)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions comparison\n",
    "plot_predictions_comparison(baseline_preds, causal_preds, baseline_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Causal Decomposition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize causal decomposition\n",
    "base_rul, cond_eff, hi_eff, total_rul, true_rul = visualize_causal_decomposition(\n",
    "    causal_model,\n",
    "    test_loader,\n",
    "    num_samples=6\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nAverage Causal Contributions:\")\n",
    "print(f\"  Base RUL: {np.mean(base_rul):.2f} cuts\")\n",
    "print(f\"  Condition Effect: {np.mean(cond_eff):.2f} cuts\")\n",
    "print(f\"  HI Effect: {np.mean(hi_eff):.2f} cuts\")\n",
    "print(f\"  Total RUL: {np.mean(total_rul):.2f} cuts\")\n",
    "print(f\"  True RUL: {np.mean(true_rul):.2f} cuts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Counterfactual Analysis - What-If Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform counterfactual analysis\n",
    "cf_results = perform_counterfactual_analysis(\n",
    "    causal_model,\n",
    "    test_loader,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nCounterfactual Analysis Results:\")\n",
    "print(cf_results.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize counterfactual results\n",
    "visualize_counterfactual_results(cf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key insights\n",
    "condition_changes = cf_results[cf_results['new_condition'].notna()]\n",
    "\n",
    "if len(condition_changes) > 0:\n",
    "    avg_delta_by_condition = condition_changes.groupby('new_condition')['delta_rul'].mean()\n",
    "    \n",
    "    print(\"\\nAverage RUL Change by Condition:\")\n",
    "    for cond, delta in avg_delta_by_condition.items():\n",
    "        orig_cond = data_dict['reverse_mapping'].get(int(cond), int(cond))\n",
    "        print(f\"  Condition {orig_cond}: {delta:+.2f} cuts\")\n",
    "    \n",
    "    best_condition = avg_delta_by_condition.idxmax()\n",
    "    best_gain = avg_delta_by_condition.max()\n",
    "    orig_best = data_dict['reverse_mapping'].get(int(best_condition), int(best_condition))\n",
    "    \n",
    "    print(f\"\\n→ Best Operating Condition: {orig_best}\")\n",
    "    print(f\"  Average RUL gain: {best_gain:.2f} cuts\")\n",
    "\n",
    "# HI reduction impact\n",
    "hi_reduction = cf_results[cf_results.get('intervention_type') == 'HI_reduction_20%']\n",
    "if len(hi_reduction) > 0:\n",
    "    avg_hi_benefit = hi_reduction['delta_rul'].mean()\n",
    "    print(f\"\\n→ 20% Wear Reduction Benefit:\")\n",
    "    print(f\"  Average RUL gain: {avg_hi_benefit:.2f} cuts\")\n",
    "    print(f\"  This demonstrates the value of improved maintenance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Counterfactual Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive example: Single sample counterfactual\n",
    "def query_counterfactual(sample_idx=0, new_condition=None, hi_reduction_percent=0):\n",
    "    \"\"\"\n",
    "    Interactive function to query counterfactual predictions\n",
    "    \n",
    "    Args:\n",
    "        sample_idx: Index of test sample\n",
    "        new_condition: New operating condition (1, 4, or 6), None to keep original\n",
    "        hi_reduction_percent: Percentage reduction in wear (0-100)\n",
    "    \"\"\"\n",
    "    # Get sample\n",
    "    batch = next(iter(test_loader))\n",
    "    seq = batch['sequence'][sample_idx:sample_idx+1].to(device)\n",
    "    orig_cond = batch['condition'][sample_idx:sample_idx+1].to(device)\n",
    "    hi = batch['health_indicator'][sample_idx:sample_idx+1].to(device)\n",
    "    true_rul = batch['label'][sample_idx].item()\n",
    "    \n",
    "    # Map condition\n",
    "    if new_condition is not None:\n",
    "        new_cond_mapped = data_dict['condition_mapping'].get(new_condition, 0)\n",
    "        new_cond_tensor = torch.tensor([new_cond_mapped], device=device)\n",
    "    else:\n",
    "        new_cond_tensor = None\n",
    "    \n",
    "    # Apply HI reduction\n",
    "    if hi_reduction_percent > 0:\n",
    "        new_hi = hi * (1 - hi_reduction_percent / 100)\n",
    "    else:\n",
    "        new_hi = None\n",
    "    \n",
    "    # Get counterfactual prediction\n",
    "    cf_result = causal_model.counterfactual_predict(\n",
    "        seq, orig_cond, hi,\n",
    "        new_condition=new_cond_tensor,\n",
    "        new_hi=new_hi\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    orig_cond_name = data_dict['reverse_mapping'][orig_cond.item()]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"COUNTERFACTUAL QUERY RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOriginal Scenario:\")\n",
    "    print(f\"  Condition: {orig_cond_name}\")\n",
    "    print(f\"  Health Indicator: {hi.item():.4f}\")\n",
    "    print(f\"  Predicted RUL: {cf_result['factual_rul'].item():.2f} cuts\")\n",
    "    print(f\"  True RUL: {true_rul:.2f} cuts\")\n",
    "    \n",
    "    print(f\"\\nIntervention:\")\n",
    "    if new_condition is not None:\n",
    "        print(f\"  → Changed condition to: {new_condition}\")\n",
    "    if hi_reduction_percent > 0:\n",
    "        print(f\"  → Reduced wear by: {hi_reduction_percent}%\")\n",
    "    \n",
    "    print(f\"\\nCounterfactual Scenario:\")\n",
    "    print(f\"  Predicted RUL: {cf_result['counterfactual_rul'].item():.2f} cuts\")\n",
    "    print(f\"  RUL Change: {cf_result['delta_rul'].item():+.2f} cuts\")\n",
    "    \n",
    "    if cf_result['delta_rul'].item() > 0:\n",
    "        print(f\"\\n✓ This intervention would EXTEND tool life!\")\n",
    "    else:\n",
    "        print(f\"\\n✗ This intervention would REDUCE tool life.\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return cf_result\n",
    "\n",
    "# Example queries\n",
    "print(\"Example 1: What if we switch to Condition 4?\")\n",
    "result1 = query_counterfactual(sample_idx=0, new_condition=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"Example 2: What if we reduce wear by 30%?\")\n",
    "result2 = query_counterfactual(sample_idx=1, hi_reduction_percent=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE\")\n",
    "print(\"-\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n2. CAUSAL INSIGHTS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Average Base RUL: {np.mean(base_rul):.2f} cuts\")\n",
    "print(f\"Average Condition Effect: {np.mean(cond_eff):.2f} cuts\")\n",
    "print(f\"Average HI Effect: {np.mean(hi_eff):.2f} cuts\")\n",
    "\n",
    "print(\"\\n3. NOVEL CONTRIBUTIONS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"✓ Structurally interpretable RUL decomposition\")\n",
    "print(\"✓ Counterfactual 'What-If' analysis capability\")\n",
    "print(\"✓ Physics-informed constraints (wear reduces RUL)\")\n",
    "print(\"✓ Decision support for process optimization\")\n",
    "\n",
    "print(\"\\n4. PRACTICAL APPLICATIONS\")\n",
    "print(\"-\" * 70)\n",
    "print(\"→ Optimize operating conditions for tool life extension\")\n",
    "print(\"→ Quantify benefits of maintenance interventions\")\n",
    "print(\"→ Support data-driven manufacturing decisions\")\n",
    "print(\"→ Enable proactive rather than reactive PHM\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(baseline_model.state_dict(), 'baseline_transformer_final.pth')\n",
    "torch.save(causal_model.state_dict(), 'causal_transformer_final.pth')\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame({\n",
    "    'baseline_predictions': baseline_preds,\n",
    "    'causal_predictions': causal_preds,\n",
    "    'actual_rul': baseline_actuals\n",
    "})\n",
    "results_df.to_csv('rul_predictions.csv', index=False)\n",
    "\n",
    "# Save counterfactual results\n",
    "cf_results.to_csv('counterfactual_scenarios.csv', index=False)\n",
    "\n",
    "print(\"Models and results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
